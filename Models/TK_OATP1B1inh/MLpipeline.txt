
(Protocosas) F:\ProtoQSAR\GENERATE_MODELS_3_0\ML_pipeline>python ML_pipeline.py

#########################################################################
##################### WELCOME TO ML_pipeline script #####################
#########################################################################
This script will allow you to:
        - generate ML models for regression or classification

Please input your PATH (enter to: "../data/TK_OATP1B1inh/"):
Please input your MODEL NAME (enter to: TK_OATP1B1inh):
######################### MAIN MENU #########################

Please select what do you want to do:
        [1] Perform a MODEL for Regression
        [2] Perform a MODEL for Classification
        [3] Exit

Your choice: 2

Please select the method used for DESCRIPTOR SELECTION:
        [1] RFE
        [2] GBM
        [3] PI
        [4] OWN


Your choice: 2
You want to perform a Classification model, by using descriptors selected by GBM.

Is that correct?(Y/n):
The following files located in "../data/TK_OATP1B1inh/" folder are needed:
TK_OATP1B1inh-train_reduction_GBM.csv
TK_OATP1B1inh-test_reduction_GBM.csv
Continue (Y/n)?

PARAMETERS:
        train molecules: 1383
        test molecules: 464
        total molecules: 1847

DESCRIPTORS: ( 20 )
['SLogP', 'Mor13m', 'PMI1', 'RDF060m', 'AATS7i', 'GATS2c', 'PEOE_VSA7', 'L2e', 'AATS2i', 'ATS0d', 'ATSC5se', 'SLogP_VSA5', 'R8s', 'SaasC', 'RNCS', 'Mor08s', 'Mor29v', 'ww', 'Mor25m', 'ATSC7i']
        mols/descriptor ratio: 69.15
PLEASE, ENSURE SEED HYPEPARAM IF USING XGB MODELS AND ENSURE REPRODUCIBILITY!!
PLEASE, ENSURE SEED HYPEPARAM IF USING XGB MODELS AND ENSURE REPRODUCIBILITY!!
PLEASE, ENSURE SEED HYPEPARAM IF USING XGB MODELS AND ENSURE REPRODUCIBILITY!!

[+] Training the model...

Best parameters for LGBMClassifier:
{'boosting_type': 'gbdt', 'class_weight': {0: 1, 1: 6}, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_samples': 20, 'n_estimators': 60, 'num_leaves': 7, 'random_state': 9, 'subsample': 0.7}

Grid test score: 0.8409224088316852
------------------------------

Best model and parameters:
LGBMClassifier(class_weight={0: 1, 1: 6}, learning_rate=0.05, max_depth=10,
               n_estimators=60, num_leaves=7, random_state=9, subsample=0.7)

Best model and parameters:
{'boosting_type': 'gbdt', 'class_weight': {0: 1, 1: 6}, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_samples': 20, 'n_estimators': 60, 'num_leaves': 7, 'random_state': 9, 'subsample': 0.7}

GridSearch parameters:
GridSearchCV(cv=5, estimator=LGBMClassifier(), n_jobs=-1,
             param_grid={'boosting_type': ['gbdt'],
                         'class_weight': [{0: 1, 1: 6}],
                         'learning_rate': [0.05], 'max_depth': [10, 15],
                         'min_child_samples': [20], 'n_estimators': [60],
                         'num_leaves': [4, 5, 7], 'random_state': [9],
                         'subsample': [0.7]},
             return_train_score=True, scoring='f1_micro')
-------------------------------

 A JSON file with the descriptors has been saved as ../data/TK_OATP1B1inh/TK_OATP1B1inh.json

######################################################
################### Model results ####################
######################################################

############### Training set results ###############

               precision    recall  f1-score   support

           0       0.99      0.88      0.93      1203
           1       0.53      0.92      0.67       180

    accuracy                           0.89      1383
   macro avg       0.76      0.90      0.80      1383
weighted avg       0.93      0.89      0.90      1383

Confussion matrix:

    OBS\PRED           0           1
           0        1059         144
           1          15         165

############### Test set results ###############

               precision    recall  f1-score   support

           0       0.95      0.84      0.89       403
           1       0.39      0.69      0.50        61

    accuracy                           0.82       464
   macro avg       0.67      0.76      0.69       464
weighted avg       0.87      0.82      0.84       464

Confussion matrix:

    OBS\PRED           0           1
           0         338          65
           1          19          42

################ Global results ###############

                |Train| Test
       acc      |0.89 |0.82
  prec_PPV      |0.53 |0.39
    recall      |0.92 |0.69
        f1      |0.67 |0.50
       auc      |0.90 |0.76
sensit_TPR      |0.92 |0.69
  spec_TNR      |0.88 |0.84
       NPV      |0.99 |0.95
       FNR      |0.08 |0.31
       FPR      |0.12 |0.16
       FDR      |0.47 |0.61
       FOR      |0.01 |0.05
   F_score      |0.67 |0.50
       MCC      |0.64 |0.42
       CSI      |0.51 |0.33

######################################################
############## Cross-validation results ##############
######################################################

        |Train          | Test
    acc |0.87 +/- 0.009 |0.83  +/- 0.022
   prec |0.51 +/- 0.020 |0.42  +/- 0.040
 recall |0.92 +/- 0.015 |0.71  +/- 0.066
     f1 |0.66 +/- 0.019 |0.52  +/- 0.045
    auc |0.95 +/- 0.004 |0.86  +/- 0.037
 sensit |0.92 +/- 0.015 |0.71  +/- 0.066
   spec |0.87 +/- 0.009 |0.85  +/- 0.023
    NPV |0.99 +/- 0.003 |0.95  +/- 0.011
    FNR |0.08 +/- 0.015 |0.29  +/- 0.066
    FPR |0.13 +/- 0.009 |0.15  +/- 0.023
    FDR |0.49 +/- 0.020 |0.58  +/- 0.040
    FOR |0.01 +/- 0.003 |0.05  +/- 0.011
F_score |0.66 +/- 0.019 |0.52  +/- 0.045
    MCC |0.62 +/- 0.021 |0.45  +/- 0.056
    CSI |0.49 +/- 0.021 |0.36  +/- 0.042

Please, close the plots to continue...

Do you want to perform any other step?(y/n):  n

Thanks for using ML_pipeline!
